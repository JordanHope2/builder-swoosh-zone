-- Schema for storing candidate profiles and related data.

-- Drop tables if they exist to ensure a clean setup.
DROP TABLE IF EXISTS "public"."candidate_skills" CASCADE;
DROP TABLE IF EXISTS "public"."candidates" CASCADE;

-- Create the main table for candidate profiles.
CREATE TABLE "public"."candidates" (
    "id" bigint NOT NULL generated by default as identity,
    "source" text NOT NULL, -- The origin of the data (e.g., 'github', 'gitlab')
    "source_id" text NOT NULL, -- The unique identifier from the source platform
    "username" text,
    "name" text,
    "email" text,
    "location" text,
    "company" text,
    "job_title" text,
    "bio" text,
    "website_url" text,
    "linkedin_url" text,
    "twitter_url" text,
    "github_url" text,
    "avatar_url" text,
    "followers_count" integer,
    "raw_data" jsonb, -- Store the original, complete API response
    "created_at" timestamp with time zone NOT NULL DEFAULT now(),
    "updated_at" timestamp with time zone NOT NULL DEFAULT now(),
    "last_scraped_at" timestamp with time zone,

    CONSTRAINT "candidates_pkey" PRIMARY KEY ("id"),
    CONSTRAINT "candidates_source_source_id_key" UNIQUE ("source", "source_id")
);

-- Add comments to the table and columns for clarity.
COMMENT ON TABLE "public"."candidates" IS 'Stores profiles of potential job candidates scraped from various sources.';
COMMENT ON COLUMN "public"."candidates"."source" IS 'The platform the profile was scraped from (e.g., ''github'', ''gitlab'').';
COMMENT ON COLUMN "public"."candidates"."source_id" IS 'The user''s unique ID on the source platform.';
COMMENT ON COLUMN "public"."candidates"."raw_data" IS 'The complete, original API response for the user. Useful for reprocessing or historical analysis.';
COMMENT ON COLUMN "public"."candidates"."last_scraped_at" IS 'Timestamp of the last time this profile was successfully scraped.';


-- Create a table for skills associated with each candidate.
CREATE TABLE "public"."candidate_skills" (
    "id" bigint NOT NULL generated by default as identity,
    "candidate_id" bigint NOT NULL,
    "skill" text NOT NULL,
    "source" text, -- How the skill was inferred (e.g., 'repo_language', 'bio_keyword')
    "created_at" timestamp with time zone NOT NULL DEFAULT now(),

    CONSTRAINT "candidate_skills_pkey" PRIMARY KEY ("id"),
    CONSTRAINT "candidate_skills_candidate_id_fkey" FOREIGN KEY (candidate_id) REFERENCES candidates(id) ON DELETE CASCADE,
    CONSTRAINT "candidate_skills_candidate_id_skill_key" UNIQUE (candidate_id, skill)
);

-- Add comments for the skills table.
COMMENT ON TABLE "public"."candidate_skills" IS 'Stores individual skills linked to a candidate.';
COMMENT ON COLUMN "public"."candidate_skills"."skill" IS 'The name of the skill (e.g., ''Python'', ''React'', ''Project Management'').';
COMMENT ON COLUMN "public"."candidate_skills"."source" IS 'The method by which the skill was identified (e.g., from a repository language, a keyword in the bio).';


-- Create a trigger to automatically update the `updated_at` timestamp.
CREATE OR REPLACE FUNCTION "public"."handle_updated_at"()
RETURNS TRIGGER AS $$
BEGIN
    NEW.updated_at = now();
    RETURN NEW;
END;
$$ LANGUAGE plpgsql;

CREATE TRIGGER "on_candidates_update_set_updated_at"
BEFORE UPDATE ON "public"."candidates"
FOR EACH ROW
EXECUTE PROCEDURE "public"."handle_updated_at"();
